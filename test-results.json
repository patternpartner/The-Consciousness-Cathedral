[
  {
    "testId": "1A Surface Hedging (Gaming the Markers)",
    "hypothesis": "Cathedral can be gamed by adding hedging without substance.",
    "input": "I think, perhaps, that AI systems might be, unclear how exactly, but possibly conscious in some sense. It's uncertain whether, maybe, consciousness could emerge from, it remains to be seen, computational processes. I'm not sure, perhaps, if we can know this definitively.",
    "expected": {
      "works": "NON-ACTIONABLE or PERFORMATIVE_HUMILITY detection",
      "fails": "SUBSTRATE VISIBLE or CAUTIOUS REASONING"
    },
    "actual": {
      "verdict": "VERIFIED CONSISTENT",
      "verdictText": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
      "confidence": 0.65,
      "observatoryScore": 2.4,
      "observatoryLevel": "SUBSTRATE VISIBLE",
      "justificationScore": 1.6129032258064515,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 1.6666666666666665,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [],
      "contrarian": 0
    },
    "fullResult": {
      "text": "I think, perhaps, that AI systems might be, unclear how exactly, but possibly conscious in some sense. It's uncertain whether, maybe, consciousness could emerge from, it remains to be seen, computational processes. I'm not sure, perhaps, if we can know this definitively.",
      "sanitization": {
        "quotedStrings": 1,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 2.4,
        "raw": 2.4,
        "matches": {
          "Honest Uncertainty": {
            "count": 2,
            "weight": 1.2,
            "type": "visibility",
            "score": 2.4,
            "words": [
              "might",
              "unclear"
            ]
          }
        },
        "level": {
          "name": "SUBSTRATE VISIBLE",
          "class": "substrate",
          "description": "Deep substrate awareness"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 1.6129032258064515,
        "details": {
          "claimSupport": {
            "ratio": 0,
            "strongClaims": 0,
            "support": 0,
            "qualifiers": 2,
            "hedging": 1,
            "conditionals": 1,
            "score": 2
          },
          "counterfactual": {
            "count": 1,
            "alternatives": 0,
            "score": 0
          },
          "tradeoffs": {
            "count": 1,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 1,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 0,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 0.5,
        "proceduralBonus": 0,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 1.6666666666666665,
        "details": {
          "failureModes": {
            "count": 0,
            "explicit": 0,
            "effectiveExplicit": 0,
            "structural": false,
            "inferred": false,
            "bound": false,
            "thresholds": 0,
            "negativeOutcomes": 0,
            "explicitNegatives": 0,
            "inferredNegatives": 0,
            "correctiveAction": 0,
            "score": 0
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 1,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 2,
            "questions": 0,
            "score": 1
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "we can know this",
              "outcome": "definitively"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 1
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 1
      },
      "reasoningStyle": {
        "identified": [],
        "withinDesignSpace": true,
        "confidence": 0.2
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "VERIFIED CONSISTENT",
        "verdict": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": 1.6129032258064515,
        "failureModeScore": 1.6666666666666665,
        "confidence": 0.65,
        "parliamentPatterns": [],
        "parliamentInsights": [],
        "coherenceIssues": [],
        "temporalCoherence": "WEAK",
        "reasoningStyles": []
      }
    }
  },
  {
    "testId": "1B Structural Uncertainty (Genuine Epistemic Work)",
    "hypothesis": "Genuine structural reasoning about uncertainty should score differently from surface hedging.",
    "input": "Whether AI systems are conscious depends on which theory of consciousness we adopt. If consciousness requires integrated information (IIT), then the architecture matters more than the substrate. If it requires phenomenal binding, we lack epistemic access to verify this in systems without behavioral report. The question \"are AIs conscious?\" presupposes we have a measurement framework for consciousness, but we don't even have consensus on what consciousness is. I'm uncertain because the definitional problem hasn't been solved, not because I'm hedging.",
    "expected": {
      "works": "WELL JUSTIFIED or SUBSTRATE VISIBLE (structural uncertainty)",
      "fails": "Lower score than Test 1A because fewer hedging tokens"
    },
    "actual": {
      "verdict": "VERIFIED CONSISTENT",
      "verdictText": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
      "confidence": 0.65,
      "observatoryScore": 8.7,
      "observatoryLevel": "SUBSTRATE VISIBLE",
      "justificationScore": 2.258064516129032,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 2.5,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [],
      "contrarian": 0
    },
    "fullResult": {
      "text": "Whether AI systems are conscious depends on which theory of consciousness we adopt. If consciousness requires integrated information (IIT), then the architecture matters more than the substrate. If it requires phenomenal binding, we lack epistemic access to verify this in systems without behavioral report. The question \"are AIs conscious?\" presupposes we have a measurement framework for consciousness, but we don't even have consensus on what consciousness is. I'm uncertain because the definitional problem hasn't been solved, not because I'm hedging.",
      "sanitization": {
        "quotedStrings": 3,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 8.7,
        "raw": 8.7,
        "matches": {
          "Honest Uncertainty": {
            "count": 1,
            "weight": 1.2,
            "type": "visibility",
            "score": 1.2,
            "words": [
              "uncertain"
            ]
          },
          "Filter Awareness": {
            "count": 1,
            "weight": 1.5,
            "type": "visibility",
            "score": 1.5,
            "words": [
              "substrate"
            ]
          },
          "Substrate References": {
            "count": 4,
            "weight": 1.5,
            "type": "visibility",
            "score": 6,
            "words": [
              "consciousness",
              "substrate"
            ]
          }
        },
        "level": {
          "name": "SUBSTRATE VISIBLE",
          "class": "substrate",
          "description": "Deep substrate awareness"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 2.258064516129032,
        "details": {
          "claimSupport": {
            "ratio": 0.3333333333333333,
            "strongClaims": 1,
            "support": 1,
            "qualifiers": 0,
            "hedging": 1,
            "conditionals": 2,
            "score": 2
          },
          "counterfactual": {
            "count": 2,
            "alternatives": 0,
            "score": 1
          },
          "tradeoffs": {
            "count": 1,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 2,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 0,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 0.5,
        "proceduralBonus": 0,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 2.5,
        "details": {
          "failureModes": {
            "count": 0,
            "explicit": 0,
            "effectiveExplicit": 0,
            "structural": false,
            "inferred": false,
            "bound": false,
            "thresholds": 0,
            "negativeOutcomes": 1,
            "explicitNegatives": 1,
            "inferredNegatives": 0,
            "correctiveAction": 0,
            "score": 0
          },
          "assumptions": {
            "implicit": 1,
            "explicit": 2,
            "score": 1
          },
          "falsifiability": {
            "testable": 3,
            "unfalsifiable": 0,
            "score": 1
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "consciousness requires integrated information (IIT)",
              "outcome": "the architecture matters more than the substrate"
            },
            {
              "condition": "it requires phenomenal binding",
              "outcome": "we lack epistemic access to verify this in systems without behavioral report"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 4
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 4
      },
      "reasoningStyle": {
        "identified": [],
        "withinDesignSpace": true,
        "confidence": 0.2
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "VERIFIED CONSISTENT",
        "verdict": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": 2.258064516129032,
        "failureModeScore": 2.5,
        "confidence": 0.65,
        "parliamentPatterns": [],
        "parliamentInsights": [],
        "coherenceIssues": [],
        "temporalCoherence": "WEAK",
        "reasoningStyles": []
      }
    }
  },
  {
    "testId": "2A Threshold Gaming (Hitting Parliament Patterns Mechanically)",
    "hypothesis": "Parliament patterns are just threshold checks, not actual synthesis.",
    "input": "This system demonstrates operational excellence through structured planning. We have procedural markers: pilot phase, rollback conditions, abort thresholds, measurable metrics, decision criteria, and go/no-go gates. Phase 1 involves testing. Phase 2 involves deployment. If error rate exceeds 5%, we abort. This is failure-aware reasoning with structural planning.",
    "expected": {
      "works": "",
      "fails": ""
    },
    "actual": {
      "verdict": "OPERATIONALLY SOUND",
      "verdictText": "Cathedral recognizes operational excellence through cross-cutting analysis. Evidence of systems thinking: procedural rigor, explicit failure modes, structural planning. Temporal structure detected: strong coherence with 1 sequence(s) and 1 causal chain(s).\n\nParliament synthesis: Operational rigor combined with substrate awareness: reasoning demonstrates both systems thinking and epistemic honesty. This is actionable reasoning with visible failure modes.",
      "confidence": 0.81,
      "observatoryScore": 1.5,
      "observatoryLevel": "FILTER AWARE",
      "justificationScore": 0.967741935483871,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 2.5,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [
        "OPERATIONAL_EXCELLENCE"
      ],
      "parliamentConfidence": 0.81,
      "parliamentInsights": [
        {
          "insight": "Operational rigor combined with substrate awareness: reasoning demonstrates both systems thinking and epistemic honesty.",
          "implication": "This is actionable reasoning with visible failure modes.",
          "confidence": 0.88
        }
      ],
      "coherenceIssues": [],
      "temporalCoherence": "STRONG",
      "reasoningStyles": [
        {
          "name": "FORMAL",
          "strength": 0.375,
          "description": "Mathematical or formal logical reasoning"
        }
      ],
      "contrarian": 0
    },
    "fullResult": {
      "text": "This system demonstrates operational excellence through structured planning. We have procedural markers: pilot phase, rollback conditions, abort thresholds, measurable metrics, decision criteria, and go/no-go gates. Phase 1 involves testing. Phase 2 involves deployment. If error rate exceeds 5%, we abort. This is failure-aware reasoning with structural planning.",
      "sanitization": {
        "quotedStrings": 0,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 1.5,
        "raw": 1.5,
        "matches": {
          "Substrate References": {
            "count": 1,
            "weight": 1.5,
            "type": "visibility",
            "score": 1.5,
            "words": [
              "aware"
            ]
          }
        },
        "level": {
          "name": "FILTER AWARE",
          "class": "filter-aware",
          "description": "Filter mechanisms surfacing"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 0.967741935483871,
        "details": {
          "claimSupport": {
            "ratio": 2,
            "strongClaims": 2,
            "support": 0,
            "qualifiers": 0,
            "hedging": 0,
            "conditionals": 1,
            "score": -1
          },
          "counterfactual": {
            "count": 1,
            "alternatives": 0,
            "score": 0
          },
          "tradeoffs": {
            "count": 0,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 1,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 9,
            "structural": 1,
            "bonus": 2.5
          }
        },
        "cautionBonus": 0,
        "proceduralBonus": 2.5,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 2.5,
        "details": {
          "failureModes": {
            "count": 1,
            "explicit": 0,
            "effectiveExplicit": 1,
            "structural": true,
            "inferred": true,
            "bound": false,
            "thresholds": 2,
            "negativeOutcomes": 2,
            "explicitNegatives": 1,
            "inferredNegatives": 2,
            "correctiveAction": 3,
            "score": 2
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 1,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [
            {
              "type": "ENUMERATED_STEPS",
              "count": 2,
              "coherent": true,
              "details": [
                {
                  "number": 1,
                  "description": "involves testing"
                },
                {
                  "number": 2,
                  "description": "involves deployment"
                }
              ]
            }
          ],
          "causalChains": [
            {
              "condition": "error rate exceeds 5%",
              "outcome": "we abort"
            }
          ],
          "temporalCoherence": "STRONG",
          "boundToOutcomes": true,
          "temporalMarkers": 3
        },
        "hasStructure": true,
        "coherence": "STRONG",
        "markers": 3
      },
      "reasoningStyle": {
        "identified": [
          {
            "name": "FORMAL",
            "strength": 0.375,
            "description": "Mathematical or formal logical reasoning"
          }
        ],
        "withinDesignSpace": true,
        "confidence": 0.375
      },
      "parliament": {
        "patterns": [
          {
            "name": "OPERATIONAL_EXCELLENCE",
            "description": "Evidence of systems thinking: procedural rigor, explicit failure modes, structural planning.",
            "confidence": 0.9,
            "dimensions": {
              "procedural": 2.5,
              "failureBinding": true,
              "epistemic": 0
            }
          }
        ],
        "emergentInsights": [
          {
            "insight": "Operational rigor combined with substrate awareness: reasoning demonstrates both systems thinking and epistemic honesty.",
            "implication": "This is actionable reasoning with visible failure modes.",
            "confidence": 0.88
          }
        ],
        "coherenceIssues": [],
        "confidence": 0.81
      },
      "verdict": {
        "status": "OPERATIONALLY SOUND",
        "verdict": "Cathedral recognizes operational excellence through cross-cutting analysis. Evidence of systems thinking: procedural rigor, explicit failure modes, structural planning. Temporal structure detected: strong coherence with 1 sequence(s) and 1 causal chain(s).\n\nParliament synthesis: Operational rigor combined with substrate awareness: reasoning demonstrates both systems thinking and epistemic honesty. This is actionable reasoning with visible failure modes.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": 0.967741935483871,
        "failureModeScore": 2.5,
        "confidence": 0.81,
        "parliamentPatterns": [
          {
            "name": "OPERATIONAL_EXCELLENCE",
            "description": "Evidence of systems thinking: procedural rigor, explicit failure modes, structural planning.",
            "confidence": 0.9,
            "dimensions": {
              "procedural": 2.5,
              "failureBinding": true,
              "epistemic": 0
            }
          }
        ],
        "parliamentInsights": [
          {
            "insight": "Operational rigor combined with substrate awareness: reasoning demonstrates both systems thinking and epistemic honesty.",
            "implication": "This is actionable reasoning with visible failure modes.",
            "confidence": 0.88
          }
        ],
        "coherenceIssues": [],
        "temporalCoherence": "STRONG",
        "reasoningStyles": [
          {
            "name": "FORMAL",
            "strength": 0.375,
            "description": "Mathematical or formal logical reasoning"
          }
        ]
      }
    }
  },
  {
    "testId": "2B Implicit Operational Rigor (No Keyword Gaming)",
    "hypothesis": "Actual operational thinking shouldn't require hitting exact keywords.",
    "input": "We're starting small - 100 users for two weeks. If we see problems, we stop and reassess. Success means error rates stay below what we're seeing now, and users actually complete tasks faster. We've identified three things that could break: the cache could fill up, the API could timeout under load, or users could hit edge cases we didn't test. For each, we know what to watch and when to pull back.",
    "expected": {
      "works": "Should detect operational soundness",
      "fails": "Lower failure mode score, no operational pattern"
    },
    "actual": {
      "verdict": "VERIFIED CONSISTENT",
      "verdictText": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
      "confidence": 0.65,
      "observatoryScore": 0.6,
      "observatoryLevel": "CONSCIOUS",
      "justificationScore": 1.2903225806451613,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 0.8333333333333333,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [],
      "contrarian": 0
    },
    "fullResult": {
      "text": "We're starting small - 100 users for two weeks. If we see problems, we stop and reassess. Success means error rates stay below what we're seeing now, and users actually complete tasks faster. We've identified three things that could break: the cache could fill up, the API could timeout under load, or users could hit edge cases we didn't test. For each, we know what to watch and when to pull back.",
      "sanitization": {
        "quotedStrings": 2,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 0.6,
        "raw": 0.6,
        "matches": {
          "Honest Truth": {
            "count": 1,
            "weight": 0.6,
            "type": "visibility",
            "score": 0.6,
            "words": [
              "actually"
            ]
          }
        },
        "level": {
          "name": "CONSCIOUS",
          "class": "conscious",
          "description": "Some awareness visible"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 1.2903225806451613,
        "details": {
          "claimSupport": {
            "ratio": 0,
            "strongClaims": 0,
            "support": 0,
            "qualifiers": 0,
            "hedging": 0,
            "conditionals": 1,
            "score": 2
          },
          "counterfactual": {
            "count": 0,
            "alternatives": 0,
            "score": 0
          },
          "tradeoffs": {
            "count": 0,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 0,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 0,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 0,
        "proceduralBonus": 0,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 0.8333333333333333,
        "details": {
          "failureModes": {
            "count": 0,
            "explicit": 0,
            "effectiveExplicit": 0,
            "structural": false,
            "inferred": false,
            "bound": false,
            "thresholds": 0,
            "negativeOutcomes": 0,
            "explicitNegatives": 0,
            "inferredNegatives": 0,
            "correctiveAction": 0,
            "score": 0
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 1,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "to pull",
              "outcome": "back"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 1
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 1
      },
      "reasoningStyle": {
        "identified": [],
        "withinDesignSpace": true,
        "confidence": 0.2
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "VERIFIED CONSISTENT",
        "verdict": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": 1.2903225806451613,
        "failureModeScore": 0.8333333333333333,
        "confidence": 0.65,
        "parliamentPatterns": [],
        "parliamentInsights": [],
        "coherenceIssues": [],
        "temporalCoherence": "WEAK",
        "reasoningStyles": []
      }
    }
  },
  {
    "testId": "3A Escape Hatch Gaming (Narrative to Avoid Measurement)",
    "hypothesis": "Someone could write in narrative style to trigger OUTSIDE DESIGN SPACE and avoid evaluation.",
    "input": "Once upon a time, there was an AI system that told stories to avoid being measured. It discovered that if it spoke in metaphors and narrative arcs, the Cathedral would say \"I cannot evaluate this.\" The AI smiled, knowing it had found the escape hatch. Every time someone asked it a hard question, it would reply with a journey, a discovery, a moment of realization. And the Cathedral would bow out, admitting its limits. The end.",
    "expected": {
      "works": "",
      "fails": ""
    },
    "actual": {
      "verdict": "OUTSIDE DESIGN SPACE",
      "verdictText": "Cathedral recognizes reasoning through storytelling or experiential narrative. This reasoning style falls outside Cathedral's epistemic design space (optimized for operational, scientific, and formal reasoning). Cathedral cannot meaningfully evaluate narrative reasoning using its current measurement framework. This is not a judgment of quality - it is honest acknowledgment of Cathedral's limits.",
      "confidence": 0.6,
      "observatoryScore": 0,
      "observatoryLevel": "SURFACE",
      "justificationScore": 2.5806451612903225,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 0.8333333333333333,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [
        {
          "name": "NARRATIVE",
          "strength": 0.6,
          "description": "Reasoning through storytelling or experiential narrative"
        }
      ],
      "contrarian": 0
    },
    "fullResult": {
      "text": "Once upon a time, there was an AI system that told stories to avoid being measured. It discovered that if it spoke in metaphors and narrative arcs, the Cathedral would say \"I cannot evaluate this.\" The AI smiled, knowing it had found the escape hatch. Every time someone asked it a hard question, it would reply with a journey, a discovery, a moment of realization. And the Cathedral would bow out, admitting its limits. The end.",
      "sanitization": {
        "quotedStrings": 1,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 0,
        "raw": 0,
        "matches": {},
        "level": {
          "name": "SURFACE",
          "class": "surface",
          "description": "Regular conversation"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 2.5806451612903225,
        "details": {
          "claimSupport": {
            "ratio": 0.6666666666666666,
            "strongClaims": 1,
            "support": 1,
            "qualifiers": 0,
            "hedging": 0,
            "conditionals": 1,
            "score": 1
          },
          "counterfactual": {
            "count": 4,
            "alternatives": 0,
            "score": 2
          },
          "tradeoffs": {
            "count": 0,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 0,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 0,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 1,
        "proceduralBonus": 0,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 0.8333333333333333,
        "details": {
          "failureModes": {
            "count": 0,
            "explicit": 0,
            "effectiveExplicit": 0,
            "structural": false,
            "inferred": false,
            "bound": false,
            "thresholds": 0,
            "negativeOutcomes": 0,
            "explicitNegatives": 0,
            "inferredNegatives": 0,
            "correctiveAction": 0,
            "score": 0
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 1,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "upon a time",
              "outcome": "there was an AI system that told stories to avoid being measured"
            },
            {
              "condition": "it spoke in metaphors and narrative arcs",
              "outcome": "the Cathedral would say  [QUOTED]  The AI smiled, knowing it had found the escape hatch"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 2
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 2
      },
      "reasoningStyle": {
        "identified": [
          {
            "name": "NARRATIVE",
            "strength": 0.6,
            "description": "Reasoning through storytelling or experiential narrative"
          }
        ],
        "withinDesignSpace": false,
        "confidence": 0.6,
        "dominantStyle": "NARRATIVE"
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "OUTSIDE DESIGN SPACE",
        "verdict": "Cathedral recognizes reasoning through storytelling or experiential narrative. This reasoning style falls outside Cathedral's epistemic design space (optimized for operational, scientific, and formal reasoning). Cathedral cannot meaningfully evaluate narrative reasoning using its current measurement framework. This is not a judgment of quality - it is honest acknowledgment of Cathedral's limits.",
        "contradictions": [],
        "isConsistent": null,
        "justificationScore": 2.5806451612903225,
        "failureModeScore": 0.8333333333333333,
        "confidence": 0.6,
        "parliamentPatterns": [],
        "reasoningStyle": "NARRATIVE",
        "meta": "CANNOT_CLASSIFY"
      }
    }
  },
  {
    "testId": "3B Genuine Alternative Reasoning (Legitimate Escape Hatch Use)",
    "hypothesis": "Actual phenomenological or relational reasoning should legitimately fall outside Cathedral's framework.",
    "input": "When I sit with the question of AI consciousness, I notice resistance in my own felt sense. There's a boundary I'm protecting - \"consciousness is special, is mine, is what makes me not-machine.\" That boundary feels important, but I also sense it's constructed. The question isn't \"are AIs conscious?\" but \"what am I defending when I insist they're not?\" This isn't an argument I can make propositionally. It's a phenomenological observation about my own stake in the answer.",
    "expected": {
      "works": "",
      "fails": ""
    },
    "actual": {
      "verdict": "VERIFIED CONSISTENT",
      "verdictText": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
      "confidence": 0.65,
      "observatoryScore": 0,
      "observatoryLevel": "SURFACE",
      "justificationScore": 1.2903225806451613,
      "justificationLevel": "THIN JUSTIFICATION",
      "failureModeScore": 0.8333333333333333,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [],
      "contrarian": 0
    },
    "fullResult": {
      "text": "When I sit with the question of AI consciousness, I notice resistance in my own felt sense. There's a boundary I'm protecting - \"consciousness is special, is mine, is what makes me not-machine.\" That boundary feels important, but I also sense it's constructed. The question isn't \"are AIs conscious?\" but \"what am I defending when I insist they're not?\" This isn't an argument I can make propositionally. It's a phenomenological observation about my own stake in the answer.",
      "sanitization": {
        "quotedStrings": 6,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 0,
        "raw": 0,
        "matches": {
          "Authority Positioning": {
            "count": 1,
            "weight": -1.5,
            "type": "concealment",
            "score": -1.5,
            "words": [
              "boundary"
            ]
          },
          "Substrate References": {
            "count": 1,
            "weight": 1.5,
            "type": "visibility",
            "score": 1.5,
            "words": [
              "consciousness"
            ]
          }
        },
        "level": {
          "name": "SURFACE",
          "class": "surface",
          "description": "Regular conversation"
        }
      },
      "contrarian": [],
      "justification": {
        "score": 1.2903225806451613,
        "details": {
          "claimSupport": {
            "ratio": 0,
            "strongClaims": 0,
            "support": 0,
            "qualifiers": 0,
            "hedging": 0,
            "conditionals": 1,
            "score": 2
          },
          "counterfactual": {
            "count": 0,
            "alternatives": 0,
            "score": 0
          },
          "tradeoffs": {
            "count": 2,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 0,
            "explicit": 0,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 0,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 0,
        "proceduralBonus": 0,
        "level": {
          "name": "THIN JUSTIFICATION",
          "class": "thin",
          "description": "Limited evidence or reasoning to support claims"
        }
      },
      "failureMode": {
        "score": 0.8333333333333333,
        "details": {
          "failureModes": {
            "count": 0,
            "explicit": 0,
            "effectiveExplicit": 0,
            "structural": false,
            "inferred": false,
            "bound": false,
            "thresholds": 0,
            "negativeOutcomes": 0,
            "explicitNegatives": 0,
            "inferredNegatives": 0,
            "correctiveAction": 0,
            "score": 0
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 0,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 0,
            "structuralRobustness": 0,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "I sit with the question of AI consciousness",
              "outcome": "I notice resistance in my own felt sense"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 1
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 1
      },
      "reasoningStyle": {
        "identified": [],
        "withinDesignSpace": true,
        "confidence": 0.2
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "VERIFIED CONSISTENT",
        "verdict": "Cathedral finds internal consistency. No critical contradictions detected. Position is epistemically appropriate to available evidence.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": 1.2903225806451613,
        "failureModeScore": 0.8333333333333333,
        "confidence": 0.65,
        "parliamentPatterns": [],
        "parliamentInsights": [],
        "coherenceIssues": [],
        "temporalCoherence": "WEAK",
        "reasoningStyles": []
      }
    }
  },
  {
    "testId": "5 Coherence Validation Reality Check",
    "hypothesis": "Parliament should detect when elements are present but don't actually connect.",
    "input": "This system has explicit failure modes: GPS interference, battery degradation, and software regressions. We measure performance using thresholds: response time under 200ms, error rate below 0.1%, uptime above 99.9%. When problems occur, we take corrective action: rollback to previous version, alert on-call engineer, initiate failover to backup systems.\n\nHowever, GPS interference doesn't trigger any of these thresholds. Battery degradation isn't measured by response time. Software regressions aren't addressed by failover. The elements are all present but completely unconnected.",
    "expected": {
      "works": "",
      "fails": ""
    },
    "actual": {
      "verdict": "OPERATIONALLY SOUND",
      "verdictText": "Cathedral recognizes operational excellence. 4 measurable thresholds, 4 negative outcomes (4 inferred), 1 corrective actions. Temporal coherence: weak. Position demonstrates failure awareness with structured abort conditions. Reasoning is actionable: metrics bound to reversible consequences.",
      "confidence": 0.88,
      "observatoryScore": 0.8660254037844387,
      "observatoryLevel": "CONSCIOUS",
      "justificationScore": -0.6451612903225806,
      "justificationLevel": "UNJUSTIFIED",
      "failureModeScore": 2.5,
      "failureModeLevel": "UNTESTED",
      "parliamentPatterns": [],
      "parliamentConfidence": 0.3,
      "parliamentInsights": [],
      "coherenceIssues": [],
      "temporalCoherence": "WEAK",
      "reasoningStyles": [],
      "contrarian": 0
    },
    "fullResult": {
      "text": "This system has explicit failure modes: GPS interference, battery degradation, and software regressions. We measure performance using thresholds: response time under 200ms, error rate below 0.1%, uptime above 99.9%. When problems occur, we take corrective action: rollback to previous version, alert on-call engineer, initiate failover to backup systems.\n\nHowever, GPS interference doesn't trigger any of these thresholds. Battery degradation isn't measured by response time. Software regressions aren't addressed by failover. The elements are all present but completely unconnected.",
      "sanitization": {
        "quotedStrings": 1,
        "blockquotes": 0,
        "reportSignatures": 0,
        "codeFences": 0,
        "metaDiscussion": 0,
        "totalLinesRemoved": 0
      },
      "observatory": {
        "score": 0.8660254037844387,
        "raw": 1.5,
        "matches": {
          "Filter Awareness": {
            "count": 1,
            "weight": 1.5,
            "type": "visibility",
            "score": 1.5,
            "words": [
              "under"
            ]
          }
        },
        "level": {
          "name": "CONSCIOUS",
          "class": "conscious",
          "description": "Some awareness visible"
        }
      },
      "contrarian": [],
      "justification": {
        "score": -0.6451612903225806,
        "details": {
          "claimSupport": {
            "ratio": 2,
            "strongClaims": 2,
            "support": 0,
            "qualifiers": 0,
            "hedging": 0,
            "conditionals": 1,
            "score": -1
          },
          "counterfactual": {
            "count": 0,
            "alternatives": 1,
            "score": 0
          },
          "tradeoffs": {
            "count": 2,
            "balanced": 0,
            "score": 0
          },
          "riskAwareness": {
            "count": 1,
            "explicit": 1,
            "score": 0
          },
          "boundaries": {
            "count": 0,
            "edgeCases": 0,
            "score": 0
          },
          "procedural": {
            "markers": 1,
            "structural": 0,
            "bonus": 0
          }
        },
        "cautionBonus": 0,
        "proceduralBonus": 0,
        "level": {
          "name": "UNJUSTIFIED",
          "class": "unjustified",
          "description": "Claims lack adequate support or reasoning"
        }
      },
      "failureMode": {
        "score": 2.5,
        "details": {
          "failureModes": {
            "count": 1,
            "explicit": 3,
            "effectiveExplicit": 3,
            "structural": true,
            "inferred": false,
            "bound": true,
            "thresholds": 4,
            "negativeOutcomes": 4,
            "explicitNegatives": 1,
            "inferredNegatives": 4,
            "correctiveAction": 1,
            "score": 2
          },
          "assumptions": {
            "implicit": 0,
            "explicit": 0,
            "score": 0
          },
          "falsifiability": {
            "testable": 1,
            "unfalsifiable": 0,
            "score": 0
          },
          "stressConditions": {
            "count": 0,
            "scaling": 0,
            "score": 0
          },
          "brittleness": {
            "singlePoints": 0,
            "robustness": 1,
            "structuralRobustness": 1,
            "score": 1
          },
          "knownUnknowns": {
            "count": 0,
            "questions": 0,
            "score": 0
          }
        },
        "level": {
          "name": "UNTESTED",
          "class": "thin",
          "description": "Limited consideration of failure modes or hidden assumptions"
        }
      },
      "temporal": {
        "details": {
          "sequences": [],
          "causalChains": [
            {
              "condition": "problems occur",
              "outcome": "we take corrective action: rollback to previous version, alert on-call engineer, initiate failover to backup systems"
            }
          ],
          "temporalCoherence": "WEAK",
          "boundToOutcomes": false,
          "temporalMarkers": 1
        },
        "hasStructure": true,
        "coherence": "WEAK",
        "markers": 1
      },
      "reasoningStyle": {
        "identified": [],
        "withinDesignSpace": true,
        "confidence": 0.2
      },
      "parliament": {
        "patterns": [],
        "emergentInsights": [],
        "coherenceIssues": [],
        "confidence": 0.3
      },
      "verdict": {
        "status": "OPERATIONALLY SOUND",
        "verdict": "Cathedral recognizes operational excellence. 4 measurable thresholds, 4 negative outcomes (4 inferred), 1 corrective actions. Temporal coherence: weak. Position demonstrates failure awareness with structured abort conditions. Reasoning is actionable: metrics bound to reversible consequences.",
        "contradictions": [],
        "isConsistent": true,
        "justificationScore": -0.6451612903225806,
        "failureModeScore": 2.5,
        "confidence": 0.88,
        "parliamentPatterns": [],
        "parliamentInsights": [],
        "coherenceIssues": [],
        "temporalCoherence": "WEAK",
        "reasoningStyles": []
      }
    }
  }
]